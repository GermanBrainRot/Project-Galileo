\documentclass{article}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mdframed}
\usepackage{csquotes}

\usepackage{xcolor} 
\usepackage[colorlinks=true]{hyperref}

\usepackage[backend=biber,style=numeric,sorting=none]{biblatex}
\addbibresource{ProjectGalileo.bib}

\usepackage{braket}

\title{A Minor Contribution to Resolving the Consistency Problem of RQM \\ \large And an Attempt at Formalization}
\author{Markus Kasperczyk}
\date{September 11, 2025}

\begin{document}

\maketitle

\newpage

\begin{abstract}
Relational Quantum Mechanics (RQM), as proposed by Carlo Rovelli, faces a challenge: it does not clearly explain why different observers should ever agree on facts. Rovelli's postulate intended to address this issue has not led to broad consensus. In this work, I propose a refinement of this postulate informed by the relativity of simultaneity, which motivates a set of broader adjustments to RQM’s core principles. I also present a preliminary formalization connecting RQM to Markov chain theory, providing a concrete framework to identify interactions that dynamically generate facts.
\end{abstract}

\newpage

\subsection*{Note}

You are reading the arXiv version of this article. If you are interested in a more philosophically engaging discussion with memes, you can find this on \href{https://github.com/GermanBrainRot/Project-Galileo/tree/for-western-audiences}{GitHub}.

\newpage

\tableofcontents

\pagebreak

\subsection*{Introduction}

In 1996/97, Carlo Rovelli introduced \cite{Rovelli_1996} the idea that descriptions of quantum systems could be observer-dependent. Here, "observer" does not refer to any "conscious" or "macroscopic" entity, but returns to the more sober and naturalistic meaning that the term used to have in physics prior to Quantum Mechanics - and which it still has in Special and General Relativity.

To motivate the idea of observer-dependence, he proposed a thought experiment which has since been pointed out \cite{laudisa2017openproblemsrelationalquantum} to be a restatement of the old thought experiment of Wigner's Friend. For the sake of clarity, I will therefore motivate Rovelli's idea starting from Wigner's Friend.

\section{Philosophy}

\subsection{Wigner's Friend: A Thought Experiment}

Eugene Wigner, like many physicists, once wondered what exactly constituted a measurement and what the mysterious "collapse of the wave function" during a measurement might mean.

For him, the collapse had to have something to do with quantum systems interacting with consciousness. Here's how he justified this:

Suppose, instead of Wigner himself conducting a quantum measurement, he would have a friend conduct the measurement. Wigner himself would stand outside of the lab. So far, so good.

Now, after the measurement, Wigner's friend comes out of the lab and is asked by Wigner about the outcome of the experiment. Notice something here: \textit{from Wigner's point of view}, if quantum mechanics is correct, the answer must at this point be described using a superposition between the different possible outcomes. It is only upon hearing (i.e. "measuring") the answer that Wigner's description can collapse to a single state.

So, does this mean that Wigner's friend was in a superposition until that point as well? Well, let's find out! Wigner asks his friend: "what did it feel like to be in a superposition?" His friend looks confused, then replies: "What do you mean? I was not in a superposition!"

And this leads Wigner to his interpretation: The collapse of the wave function must have been caused by the measurement outcome being understood by his friend's consciousness.

This view has since been challanged in various ways. Today's consensus seems to be that it's not about consciousness, but about interactions with macroscopic environments which "decohere" into a single classical reality (more on this idea later).

In his key contribution, Rovelli added his own unique take: What if Wigner's friend truly \textit{is} in a superposition - \text{for} Wigner? Yes, you read this right: Rovelli's solution boils down to stating that superposition for me can be facts for thee and vice versa.

In particular, this means that for Rovelli, the wave function is epistemic: it's just a book keeping tool to account for the state of systems that you have not interacted with yet.

This is a very good idea. It's the type of idea that got us from Newtonian physics plus weird Lorentz transformations to account for the constancy of the speed of light for any observer to Einstein's relativity - and Rovelli is bold enough to draw this comparison himself in his initial paper.

Except, it doesn't quite work. Here's the problem:

If something can be a fact for one party (say, Alice), in limbo for another party (say, Bob) and once again a fact for a third party (say Charlie), who or what guarantees that Alice's and Charlie's facts agree once Bob learns of Alice's and Bob's notes?

In 2022, Adlam and Rovelli \cite{pittphilsci20469} modified RQM to include the following postulate:

\blockquote[Adlam/Rovelli]{
In a scenario where some observer Alice measures a variable V of a system S, then provided that Alice does not undergo any interactions which destroy the information about V stored in Alice’s physical variables, if Bob subsequently measures the physical variable representing Alice’s information about the variable V, then Bob’s measurement result will match Alice’s measurement result.
}

This attempt attempt is not without merits. At least, it hints at an ontology that could be responsible for this to work: each observer just carries the information about their measurement records around in some way, for example in correlations between observables. Nice! We avoid hidden variables simply by using \textit{statistical correlations themselves} as the locus of physical information. Very elegant move!

But somehow, this is still quite slippery. Rovelli's idea how all this fits together forces him to write something like this:

\blockquote[Adlam/Rovelli]{
This postulate implies that the information stored in Alice’s physical variables about the variable V of the system S is accessible in principle to any observer who measures her in the right basis, so at least at an emergent level this information about V is an observer-independent fact.
}

Excuse me? What if I measure her in the wrong basis? Is the information forever inaccessible to me? What does measuring "someone" in the wrong basis even mean?

To me, this sounds like Rovelli's interpretation slips right back into some version of Many Worlds - a criticism that the notion of "relative facts" has invited from the start. And indeed, the "fix" for this is to be found in the exact same place as with Many Worlds, as the "at an emergent level" part of the sentence I quoted gives away:

\blockquote[Adlam/Rovelli]{
It is clear that decoherence should play some role in this story. And in fact, decoherence provides exactly what it needed here: it picks out a basis which is dynamically favoured and then disseminates information stored in that basis through the environment.
}

But if the wave function is supposed to be epistemic, what exactly is it that "decoheres" here? Certainly not quantum branches, right? How can a set of systems "decohere" into a single reality - unless you basically allow an ontic wave function and even Everettian branching again?

Unfortunately, it seems that not much more has been written on this matter. At least as far as I am concerned, the mysteries have not \textit{quite} gone away. If we invoke decoherence to explain the "emergence" of stable facts at the macroscopic level, we would have to say \textit{what} decoheres. So, back to the drawing board!

\subsection{Refining Rovelli}

What if we went a little further than Rovelli and simply treated facts as facts? That is: \textit{measurement bases be damned}, once an interaction happened, \textit{it is a fact}.

But hold on! Is this not in a direct contradiction with the idea that facticity or superposition should be \textit{relative} to an observer, that is, \textit{observer-dependent}? How can an interaction that happened \textit{just be a fact} when \textit{at the same time} we require that another observer who doesn't know about the interaction record yet could somehow still \textit{validly} describe the situation as a superposition?

The answer is actually somewhat obvious once you read it.

All that we have to do here is to invoke Special Relativity. In Special Relativity, whether an event has happened or not is \textit{relative} to the observer. Just because the interaction already resides in the causal past of Wigner's friend, this does not mean that it is already in Wigner's causal past.

The above insight leads to a natural refinement of RQM. It is \textit{not} an ad-hoc axiom or postulate, it is \textit{well motivated} by known physics:

\textbf{Interaction records are factual for any pair of observers such that the interaction resides in the intersection of their causal past.}

If we simply dump everything we consider a definite fact into the shared causal past of all the observers for whom we require agreement, these facts can simply not bother any other observer; for there are only two other types of observers:

\begin{itemize}
\item Those who can never interact with the fact because, for example, they have fallen into a black hole  
\item Those for whom the fact lives in the future and for whom the wave function is the absolute horizon
\end{itemize}

\textbf{It would appear that we can have definite facts in the universe again!}

Except, what implications does this have? Let us think about Rovelli's philosophy a little more carefully.

If interaction records can now just be facts, doesn't that mean that we don't \textit{need} decoherence to explain how facts come into the world? Actually, it would appear that decoherence has a completely \textit{different} role in such a more realist picture: it would basically just quantify to what extent small things have more ways \textit{not to} interact, which would naturally mean that its relational properties are ill-defined.

Think of it this way: If I was an astronaut floating through space, I could always in principle triangulate my position in relation to distant stars. An electron does not have that luxury, as it is so small that the photons coming from the stars may simply miss it. In that case, \textit{neither the electron nor the universe} knows where the electron is at these times.

Which leads directly to another important refinement to Rovelli's ideas.

Rovelli's main point is that world descriptions should be \textit{relative} to the observer. Rovelli himself then correctly concludes from this that the observer is \textit{part} of the universe and we can not describe the universe "from nowhere in particular".

Once again, an observation that makes perfect sense. But how to operationalize this? Alas, Rovelli is a little shy here. He assumes that Quantum Mechanics is basically complete, so we can just use its formal apparatus and maybe derive it from an axiomatic basis that makes sense. RQM does not give us much in terms of putting its postulates into a form so we could hope to make mathematical use of them.

Therefore, I tried to tease out what I could from the above insight on a philosophical level.

Let us start with a simple observation: in everyday language, relativity "removes" facts. This is, I think, the trap that Rovelli has fallen into. What relativity \textit{actually} does is that it \textit{refines} our notion of what counts as a fact.

In mathematics, this is well known. It is the reason why we pin objects down "up to isomorphism" and work out properties that are invariant under these isomorphisms. In category theory, this concept is known as "universal properties". And in theoretical physics, there is a notion of "gauge invariance" that is related to this.

In the narrow sense, a gauge (here: Yang-Mills gauge) can be thought of as a set of symmetries so that contributions to interactions are redundant and naively summing them all up would over-count. It's basically a very fancy $dx$ in an integral.

In a broader sense though, we come right back to the familiar notion from pure mathematics: if we know how spacetime works, we can change our coordinates - and whatever changes we observe through such a move, we would not interpret them as a change of the physical \textit{facts}. That is: what is a fact is that which is left invariant under all admissible perspective changes.

With this, we are prepared to reason more carefully about the in-universe observers and their epistemic wave functions.

If I am a measurement aparatus, what is measurement \textit{about} from my perspective? Fundamentally, it is about \textit{other} quantum objects, \textit{not} about me. I can not measure myself directly! I \textit{can} measure what \textit{other} objects are doing, but I must infer anything about myself from observations of the rest of the world. Whatever we do: to get a \textit{complete} picture of reality, we must try to learn not only about the outside world, but also about ourselves and our causal impact \textit{by using the universe as a mirror}.

This suggests that we have to restrict what we mean by "fact" to anything that is true from the point of view of any observer \textit{as we leave this observer out of the picture}.

Here, it also becomes a bit clearer what an "observer" could even be. In essence, it's a set of correlated observables moving from one interaction to the next one. In general, such a "causal principle" can branch apart: just because the N observables all participated in one interaction, this doesn't mean that all N of them will participate in the next interaction - this should actually be more of an exception in general. But under certain circumstances, we end up with self-reinforcing interactions so we can treat all the involved observables as one very complex "macroscopic" observable.

One final thing needs to be pointed out about the epistemic wave function: if we take Rovelli's relativity completely seriously, we're actually forced to treat the wave function not \textit{just} as epistemic, but as \text{both} epistemic \text{and} ontic at the same time now. Which also answers why it seems to difficult to commit to either stance.

Pause here if you need another minute to see if you can figure out why.

Ready?

Well, if the observer lives \textit{inside} the universe, then \textit{his} epistemic wave function through which he understands the past and predicts the future \textit{must be physical}.

\subsection{Summary of my two Postulates}

Let me repeat my two postulates again for clarity.

1. Real facts live in the causal past that any set of given observers share in common; that is: they live in the intersection of their past light cones. Access to those facts is granted through interactions, and consistency becomes possible because facts are just facts.

2. Whatever counts as physically real must be invariant under perspective changes between different quantum observers which I take to mean any maximal set of correlated observables that participate in two successive interactions that matter to the dynamics we try to describe. This includes facts about particles at a given time that have been revealed through interactions (and that would not have meaning outside of the context of an interaction); but what is real \textit{also} includes the wave function associated to each observer which \textit{for them} can be interpreted as the epistemic connective between past and future - the substrate of cause and effect. A \textit{perspective} is a description of the world that "leaves the observer out of the picture", that is, the observer is a set of \textit{hidden variables} that he can only know about via inference over the outside world.

With all of this, Bell's beables \cite{laudisa2023evolutionbellnotionbeable} become \textit{becomables} which live at the same time at the point of an interaction \textit{and} in the onto-epistemic wave functions growing out of interactions.

\section{Formalization}

\subsection{Guiding Principle}

Here is where it becomes tricky. If we want actual facts, it would seem that we somehow have to smuggle the Born rule into our dynamics in a principled way without breaking the math.

So far, interpretations of Quantum Mechanics ranged from "let's not think about this too hard" (Copenhagen) to mathematically questionable assertions that entanglement and decoherence could by themselves account for measurement (for example Many Worlds or RQM as it stands right now).

In this category, a more recent attempt would be the philosophy of the early J. Barandes \cite{barandes2014minimalmodalinterpretationquantum}. He is more bold than Rovelli when it comes to facts being facts, but in order to make that work (and here, he is less bold than Rovelli) introduces states that are \textit{completely} epistemic - even more so than in Rovelli's picture. Our observer can only interpret the world, when the point is to explain how and why we can \textit{change} it.

A novelty in Barandes' old picture from back then (which has since evolved mostly on the formal level - his philosophy seems not to have changed much) that deserves mention is that at least officially, he gives decoherence a different role than everyone else: by having ontic facts be facts, decoherence is free to act only on epistemic states.

Except that in reality, they never decohere so much that we would ever be fully justified to apply the Born rule. A trillion interactions is still not the same as a mathematical limit. Our detached out-of-universe observer is condemned to eternal indecision and nagging philosophical questions. Sad!

The \textit{later} Barandes \cite{Barandes_2025} contributes a lot of formalism to make his ideas more precise. In his recent work, Barandes finds a different way to derive the Born rule from his axioms. This is \textit{very} interesting, but given the hard constraints of the Schrödinger equation, this either means that the derivation contains an error that has not yet been noticed or that his axioms are in a subtle way \textit{different} from standard Quantum Mechanics. The latter would be a far more exciting option, as his work seems internally consistent.

The precedent of Barandes' work indicates that it \textit{might} be possible to find a principled place where to apply the Born rule. And this naturally sets the stage for my attempt. I am specifically looking for a criterion when two observers could be described as "interacting" with each other and in what states, and for a mathematical formalism that allows me to just use the Born rule, Schrödinger equation be damned (so long as I can justify that predictions differ only subtly).

\subsection{The Math}

\subsubsection{History}

Since I am a mathematician and am a bit confused about the mathematicial dialect physicists speak, allow me to first introduce some notational "main characters" that show up all over the place.

Enter the "bra" $\bra{\psi}$ and the "ket" $\ket{\phi}$. These are just handy ways to denote row and column vectors in $\mathbb{C}^n$.

The setting that is appropriate to discuss my ideas is unitary evolution. But let us take a moment for a quick historic detour.

Historically, the first description of the full quantum state dynamics (as we currently understand it) was given by Schrödinger with his famous differential equation (see e.g. \cite{Lecture25}):

\begin{align*}
i\hbar \frac{d}{d t}\psi(t) = H(t)\psi(t).
\end{align*}

Here, $i$ is the imaginary unit, $\hbar$ is a constant known as Planck's constant and $H$ is a (in general time dependent) Hermitian operator called "Hamiltonian".

In the time \textit{in}dependent case, the solution is relatively straightforward (see derivation in the linked source):

\begin{align*}
\ket{\psi(t)}=\sum_n c_n(t_0)e^{-iE_n(t-t_0)/\hbar}\ket{n}.
\end{align*}

But in the time \textit{dependent} case, a general approach to practically solve the equation that even lends itself to numerical simulation is due to Feynman (see, for example, \cite{Perepelitsa_PathIntegrals}): just discretize time steps, and whenever you have a wave function $\psi(t)$ at time $t$, the wave function at time $t+\delta t$ becomes, in each component, the sum over all possible complex continuations of the evolution:

\begin{align*}
\ket{\psi(t+\delta t)}\approx \ket{\psi(t)}+\frac{d}{dt}\ket{\psi}\delta t=\ket{\psi(t)}-\frac{i}{\hbar}H(t)\ket{\psi(t)}\delta t,
\end{align*}

where the minus sign comes from dividing by $i$.

Now, remember what this is supposed to encode though: we want to map complex unit vectors to complex unit vectors which locally should basically be a rotation which in complex math should involve an exponential. And here it is:

\begin{align*}
\ket{\psi(t+\delta t)} \approx U(t+\delta t, t) \ket{\psi(t)}, \quad
U(t+\delta t, t) \approx \exp\Big(-\frac{i}{\hbar} H(t)\, \delta t \Big)
\end{align*}

where U is supposed to be a "time ordered" exponential.

Another way of looking at something that locally should be a rotation is multiplication with time dependent unitary operators. And lo and behold: $U$ is indeed unitary according to standard literature.

Since $H$ is technically an arbitrary Hermitian matrix that just so happens to encode something that physicists care about, a more statistics minded community has turned the path integral into a different possible foundation \cite{Luty2007PathIntegrals} of quantum mechanics based on successive application of unitary matrices.

As a pure formalism devoid of statistical interpretation, this is quite similar to what Markov chains (see \cite{LevinPeres2017}) do - which I happen to know a thing or two about.

\subsubsection{Unitary/Markov Analogy}

For my picture, I will put the Markovian and the Unitary picture side by side in a discretized form, while keeping the nice integral touch:

\begin{align*}
\ket{\psi(t)} \approx \sum_{j=0}^n \ket{\psi(0)} d P(j\cdot\delta t),
\end{align*}

and we hope that mathematicians don't hurt themselves when taking the limit $\delta t \to 0$. This formulation can be thought of as unitary or Markovian evolution for now.

To arrive at dynamics for \textit{coupled} systems, the underlying state space should be a cartesian product of possible states of the different protagonists.

In the Markov chain community, this is a no-brainer - that's how they do it.

In Quantum Mechanics though, the pairing of states is done only \textit{after} moving to quantum "probabilities" (amplitudes), leading to tensor products which appear mathematically awkward. So this may already be \textit{the} the notational contribution that appears to be originally due to the later Barandes (cited above) that makes what I am trying to do at all possible (though I do this in a different way than him).

Just for the skeptical physicist: We are \textit{not} talking about a Cartesian product of Hilbert spaces, we are talking about a Cartesian product of the underlying \textit{configuration} spaces. You \textit{should} be aware that 

\begin{align*}
\bigotimes_{i \in I} L^2(K_i) \cong L^2(\prod_{i_\in I}K_i).
\end{align*}

This is not a new insight. It's just that no one has seriously explored a construction based on the other side of the equation, that is, starting from Cartesian products.

And just to make it abundantly clear: the notion of entanglement \textit{can} be expressed in this picture, as carries over verbatim from correlated random variables:

\begin{align*}
\psi(A, B) \neq \psi_1(A) \cdot \psi_2(B)
\end{align*}

for any $\psi_1$ and $\psi_2$.

Historical note: I made this shift in notation independently of Barandes (I am only vaguely familiar with his formalism-heavy work) because to someone coming from the stochastic processes angle, it's awfully natural. It doesn't make computations intractable either, because you can still exploit sparse vector math. All it does is to clarify the picture.

Except, Barandes - instead of just doing the normal thing to just do unitary evolution based on a Cartesian configuration space - builds an entire "unistochastic" edifice on top of all that. But why? That does seem a bit like complete overkill that only adds confusion. The Markov chain notation provides all we need: we just need to switch out stochastic matrices with unitary matrices and probability vectors with complex vectors of complex unit length. The real innovation here is to do what the Markov chain people already do (and what Barandes did!) and describe coupling by moving to a Cartesian product of each entities' possible configurations.

In other words: \textit{my} idea here is to draw out as many analogies from Markov chains as you can and see where it breaks. That's all we need to do.

\subsubsection{Markovian Example}

Let us now think, for example, of two billiard balls $A$ and $B$, each with $\mathbb{R}^2$ as position space (remember that billiard balls move on tables):

\begin{align*}
S_{A,B} = \mathbb{R}^2\times\mathbb{R}^2 = \mathbb{R}^4.
\end{align*}

In this now rather inconveniently encoded state space (but remember that with Cartesian products, switching to other representations than a 4-vector is mere childsplay), we can introduce dynamics via a random walk on each participant, where we restrict ourselves to just the four major axes and a single step-width:

\begin{align*}
P(X(t+\delta t) = y \mid X(t) = x) = \begin{cases}
&\frac{1}{4} \text{ if } y = x\pm v\cdot e_i,\\
&0, \text{otherwise}
\end{cases}, X=A\lor X=B. 
\end{align*}

Now, say that the billiard balls are dot sized and whenever they occupy the same place, we want them to collide. To make our mathematical lives easy and not think about momentum for now (we're drunken billiard balls!), let's just have the protagonists do something completely unphysical to get the point across: they'll just move together in their drunkards walk.

Here's how the dynamics looks in the Markovian picture:

\begin{align*}
P((A,B)(t+\delta t) &= y \mid (A,B)(t)=x \land A(t_-) = B(t_-) \text{ for some } t_- \leq t) \\
&= (\text{see above}).
\end{align*}

Notice something? We somehow had to completely change the system dynamics to make that happen. Now, the two billiard balls no longer have their own transition probabilities, but they are updated together so as to maintain their correlated state.

This has \textit{nothing} to do with the fact that we asked them to move together. I chose this example to keep the system simple. What I want to draw your attention to here is that both random variables from now into perpetuity depend on a single, shared "coin toss".

\textit{This} is what Bell was getting at with his famous theorem: in a classical Markovian picture, correlation forces us to introduce \textit{global} dynamics to maintain it.

Sure: you could also have added momentum and imposed a realistic constraint on the correlation of the momenta after the interaction. But to make this correlation \textit{stick}, you would have to make the momentum dominate position evolution, and the momentum itself would basically have to be deterministic. Otherwise, over time, the correlation imposed this way will still degenerate in the Markovian picture.

Not so in the unitary picture!

It is a well known fact \cite{Hulpke_2006} that unitary evolution in the non-interacting case preserves entanglement - the quantum analogy of correlation.

An "\textbf{interaction}" is just a situation where the dynamics and the prior state make it so that

\begin{align*}
&P((A,B)(t+\delta t) | (A,B)(t)) \\ \neq &P(A(t+\delta t)\mid A(t))\cdot P(B(t+\delta t) \mid B(t)),
\end{align*}

and a valid "\textbf{interaction outcome}" in \textbf{both the Markovian and Unitary picture} is just a pair of states (think: both billiard balls at the same place, but this is just modelling choice in my toy model) such that

\begin{mdframed}
\begin{align*}
&P((A,B)(t+\delta t) = (x,y) | (A,B)(t)) \\ \neq &P(A(t+\delta t) = x\mid A(t))\cdot P(B(t+\delta t)=y \mid B(t)).
\end{align*}
\end{mdframed}

We literally \textit{introduce} a correlation/entanglement dynamically - and unitary evolution preserves it as long as there are no further interactions in the above sense. That's all there is to it.

\subsubsection{Small Sparsity Exploit}

One \textit{very} neat thing that comes out of this way of wording the \textit{process} of entanglement is that the valid interaction outcomes are "marked". If we think of the entire probability or quantum state, it would assign a probability or amplitude to each possible configuration. But with the above observation, we can do the following:

Given an interaction happens at $t\mapsto t+\delta t$. Let $I$ be the set of all valid interaction outcomes. Then, we can encode the entire posterior joint state $P_{\text{post}}$ (probability or quantum) as

\begin{align*}
P_{\text{post}}(A,B) = P_{\text{post}}(A,B) \odot 1_I \ ?? \ P_{\text{post}}(A)\cdot P_{\text{post}}(B)
\end{align*}

where $\odot$ is the pointwise product, $1_I$ is a 0/1 indicator whether we are in $I$ or not and $??$ is an operator inspired by modern programming languages like Swift which here has the meaning

\begin{align*}
A(i) \ ?? \ B(i) := B(i) \text{ if } A(i) = 0, A(i) \text{ otherwise}.
\end{align*}

If interactions are rare or only have a small amount of possible outcomes, this should lower the required storage space in a simulation.

\subsubsection{Markovian versus Unitary Modelling}

Now, how do we model dynamics in general? This is where the two pictures truly differ. In the Markov case, we have to preserve stochasticity, in the unitary case, we have to preserve unitary norm and (traditionally) angles.

In the \textbf{Markov} case, we can just decompose the transition matrix into a mixture stochastic matrices that act on each subsystem:

\begin{align*}
 P((A,B)(t+\delta t) = (x,y)\mid (A,B)(t)) &= \alpha P((A)(t + \delta t)\mid A(t))\\ & + \beta P(B(t+\delta t) \mid B(t)) \\ & + \gamma P_{\text{int}}((A,B)(t+\delta t) = (x,y)\mid (A,B)(t)), 
 \end{align*}

where $P_{\text{int}}$ encodes the coupled dynamics. Notice something though: $\alpha$, $\beta$ and $\gamma$ are \textit{not} probabilities. To make this work, they can not even be thought of as scalars! In order to preserve global stochasticity, one would have to scale \textit{each row} (encoding a state before transition) so that the probabilities sum to 1 between the individual transition matrix and the interaction matrix. That is, they would have to be diagonal matrices multiplied from the right that fit together in an odd way.

Alright, second attempt!

\begin{align*}
 P((A,B)(t+\delta t) = (x,y)\mid (A,B)(t)) &= \alpha P((A)(t + \delta t)\mid A(t))\\ & + \alpha P(B(t+\delta t) \mid B(t)) \\ & + (1-\alpha) P_{\text{int}}((A,B)(t+\delta t) = (x,y)\mid (A,B)(t))? 
\end{align*}

Ok, now we have modelled it with a single scalar so we can think of this as a probability whether we interact or not. Except... This doesn't work either! If we want to preserve correlations indefinitely, the non-interacting terms would have to vanish the moment we interacted and the dynamics would have to snap into a contrived joint dynamics.

So, while this is something that Markovians have been implicitly doing all the time, saying it out loud makes explicit just how problematic this is.

In the \textit{unitary} case, one has to decompose the joint dynamics into a product:

\begin{align*} 
U((A,B)(t+\delta t) = (x,y)\mid (A,B)(t)) &= U((A)(t + \delta t)\mid A(t))\\ & \cdot U(B(t+\delta t) \mid B(t))\\& \cdot U_{\text{int}}((A,B)(t+\delta t)\mid (A,B)(t)),
\end{align*}

which sounds like complete nonsense if you think of these as transition probabilities. To keep our sanity, we must think of these as correlation transport terms or "transition amplitudes" and drink some vodka.

Minor note: the "$\mid$" in $U((A)(t + \delta t)\mid A(t))$ is supposed to denote that we are deriving this mathematical object from the full transition matrix in the same way as we would in the case of a stochastic matrix: by multiplying a row with the current state vector. But we \textit{remain} in the unitary picture!

What these terms \textit{are} doing for us is make it clear how and why correlations are actually preserved here: the multiplication of unitary operators can readily be understood as \textit{function chaining} which means that here, everyone does indeed "get their own dice roll".

One thing to keep in mind though is that due to the interaction terms, the \textit{order} of the factorization matters now. Products of matrices do not commute! So, the above representation is just one possibility - which is why we had that "time ordered exponential" in the Feynman picture. This really just means that in the exponent, we have to treat the sum as ordered.

But how do we model dynamics now? Intriguingly, this is where the Hamiltonian shows up again in this probabilistic picture:

\begin{align*}
 U((A,B)(t+\delta t) = (x,y)\mid (A,B)(t)) &= \text{exp}\big (-i( H^A_{t \to t+\delta t} + H^B_{t \to t+\delta t} + H^{\text{int}}_{t \to t+\delta t}) \big ).
 \end{align*}

The way physicists encode dynamics in the Hamiltonian is to express everything in units of energy and they use physical dimensions to make sure that whenever they add a term, they don't violate Hermitian-ness.

\subsubsection{Probabilities}

We have carried the analogy between Markovian and Unitary dynamics \textit{very} far. It seems almost like all is good now!

Except that in the unitary picture, we have so far not seen a single thing that we could interpret as a probability. And honestly? This is a little mysterious. Think about it this way: we now have a dynamical system that can somehow introduce "correlations" - but what are the correlations \textit{about}?

This is where my second postulate steps in, which says three things here:
\begin{itemize}
\item Facts are whatever is true at interaction, independent of which observer's perspective we choose.
\item We do not need decoherence to explain facts. Decoherence can go and explain something else.
\item Interactions are \textit{mutual} quantum Bayesian updates between observers, where "observer" or "Bayesian" does not require consciousness or any of that voodoo.
\end{itemize}

Ok, so mutual Bayesian update. What could that mean? Let us consider an actual typical quantum experiment: a macroscopic measurement instrument $A$ and an electron $B$ which have just interacted according to dynamic $U$ on interaction outcome set $I$.

For this, the Measurement device uses \textit{some} way to come up with a probability distribution on the electron's Hilbert space.

Enter Gleason's Theorem \cite{Gleason1957}. Gleason says that the \textit{only} way to do that is the Born rule.

In my picture, this would essentially mean

\begin{align*}
\widehat{U}((A,B) = i) = \|U((A,B) = i)\|^2
\end{align*}

whenever $i\in I$. \textit{Except} this doesn't sum to 1. In fact, if we do this naively, our entire wave function $U$ does not have norm 1 anymore!

Alright, so let's refine this. Let us begin by assuming we marginalized everyone who does not participate in this interaction out. Then, we are now left with the wave function only of the interaction participants.

Here is the problem: we have not quite marginalized out everything that we should. The "plug in a 1" part works for a single configuration, but not if it is paired with a ton of irrelevant configurations. If these were finitely many irrelevant configurations, we could maybe assign equal weight to every configuration that keeps the component we care about the same. But if the marginal configuration is paired with a non-compact configuration space, an "equal weight" for all copies becomes ill-defined! 

The mistake here is defining interactions broadly as a situation between observers. With this move, we have discarded the important nuance that the observers may interact in different ways, not just with different outcomes. So, how do we find these "different ways"?

Let us re-index our joint quantum state with observables $O_I$. In essence, we are looking for configurations $j\in I$ such that

\begin{align*}
P(O_I) = P(O_i) \cdot P(O_{I\setminus\lbrace i\rbrace}).
\end{align*}

Can this be done in some unique way? Can we somehow partition our interaction condition into different interactions?

Indeed, we can! Conditional probabilities/amplitudes help us here. Let $X$, $Y$ and $Z$ be observables. We can call $X$ and $Y$ \textbf{directly interdependent}, if either

\begin{align*}
P(Y) &\neq P(Y\mid X) \text{ or} \\
P(X) &\neq P(X\mid Y).
\end{align*}

We note that this relation is in general not transitive: if $X$ and $Y$ are directly interdependent and $Y$ and $Z$ are directly interdependent, this does not mean that $X$ and $Z$ are directly interdependent (in such a situation, literature calls $X$ and $Z$ "conditionally independent"). For our purposes, we are interested in the transitive closure - that is: if $X$ and $Y$ are directly interdependent and $Y$ and $Z$ are directly interdependent, we call $X$, $Y$ and $Z$ \textbf{interdependent}.

By trivially having $X$ be interdepentent with $X$, interdependence forms an \textbf{equivalence relation} which allows us to partition $O_I$ into equivalence classes of different interactions. Let us denote interdependence as $\sim$ and let us define $\mathcal{O}_J = \frac{O_I}{\sim}$ where I have omitted the step that I am actually re-indexing and hope that the reader understands what is going on here.

Now, we can do what we set out to do. For a given $O\in\mathcal{O}_J$, we marginalize out all observables that are irrelevant:

\begin{align*}
P(O) = \sum_{O^\prime \text{ observable}, O^\prime \notin O} P(O\mid O^\prime) P(O^\prime).
\end{align*}

\textit{Now} we are in a situation where the Born rule makes perfect sense: for any $o\in O$ (where we have to keep in mind that $o$ is a tuple here),

\begin{align*}
P_{\text{Born}}(o) = \|P(o)\|^2
\end{align*}

where $P$ represents our wave function.

\textbf{All that unitary evolution does is introducing and transporting correlation. In my picture, states where interactions (correlation introduction) happen are explicit and therefore, we have a natural place to apply the Born rule and obtain probabilities that naturally encode how likely it is for the involved participants to participate in a certain interaction at a given time.}

\subsubsection{How to Zoom Back Out?}

In order to recover, from the perspective of an individual interaction, the entire wave function, we can use Kraus operators (see for example \cite{griffiths_qitd412}). These have been around since 1971! Kraus himself apparently did not quite know where and when to apply them, but he did point out that they allow to include the Born rule into Quantum Mechanics in a coherent manner going \textit{beyond} unitary evolution.

Over the years, physicists have found a few intuitions where the Kraus operator should be applied: open systems, strong decoherence regimes and so on. The novelty in my approach lies not in finding a way to include the Born rule as an axiom (in a sense, Kraus already did that) but finding a principled place where to do that that.

For the sake of completeness, let me spell out what the Kraus operator does and what it looks like in my picture.

In essence, we look at each possible realization $o_i$ of $o$. Keep in mind that in my Cartesian picture, this is just a configuration of $o$. In the probability space we just found through marginalizing everything else out and applying the Born rule, obtaining $o_i$ means that we would assign probability $1$ to this configuration and $0$ to everything else - an operation formally known as the Dirac delta at $o_i$, or $\delta_{o_i}$.

That is, for each configuration $o_i$, we can say what the wave function should be if $o_i$ is the realized outcome:

\begin{align*}
P_{o_i}(\Omega) \sim P(\Omega)\cdot \delta_{o_i}
\end{align*}

where $\sim$ means that we need to normalize, and then

\begin{align*}
\widehat{P}(o \times \Omega) \sim \sum_{o_i\in o} P_{o_i}(\Omega) dP_{\text{Born}}(o_i)
\end{align*}

with the same normalization caveat.

Philosophical note: this is precisely the mathematical realization of "what is globally true must be true in each perspective". The global picture re-emerges \textit{from} perspectives. The wave function so recovered is unique up to global phase, which, according to my understanding or relativity, marks the global phase as non-physical.

\textit{However}, this is just for all configurations relevant to \textit{one specific} interaction. This is where we have to consider one more concept: so-called "mixed states". Basically, these are classical probabilistic mixtures of wave functions - which makes perfect sense here, because we just "collapsed the wave function" into a probability distribution.

Notation-wise, our Cartesian picture once again makes our live comparatively easy as a mixture of wave functions is just that: a probabilistic mixture of elements of some set that in the probabilistic picture, we can treat as a black box.

\begin{align*}
\widehat{P}_{\text{interact}}(\mathcal{O}\times\Omega) = \ket{p_o \widehat{P}(o\times\Omega)}_{o\in\mathcal{O}}
\end{align*}

where the $p_o$ sum to $1$ (this is still not the full picture, we are still assuming that we actually interacted!). How to derive the $p_o$? In order to stay consistent, these should be the aggregated Born measures:

\begin{align*}
p_o \sim \sum_{o_i\in o}P_{\text{Born}}(o_i)
\end{align*}

Note that this is independent of which interaction-participant looks at it.

Finally, in order to bring all the states where the two observers \textit{don't} interact back into the picture, observe that the states where the two don't interact are again \textit{joint} configurations of both objects. Therefore, their contribution to the joint Born density is in theory well-defined. Let's all all these configurations $u$. They are associated with the standard unitary wave function $P$ where you \textit{only} get entanglement. Therefore,

\begin{align*}
\widehat{P}(u\times\mathcal{O}\times\Omega) = \ket{p_o \widehat{P}(o\times\Omega)}_{o\in\mathcal{O}\cup \lbrace u\rbrace}.
\end{align*}

Philosophical note: by "you \textit{only} get entanglement, I of course do not mean that we now get pure correlation that is about nothing. The whole point of this investigation was to make correlations about something! So what are they about in the non-interacting case?

Non-interaction! We are talking about a situation when an interaction \textit{could have} happened, but didn't. This means precisely that our two observers were \textit{not} in a configuration where an interaction took place. This is a \textit{negative} constraint, a \textit{recorded fact} in the book of the universe that all subsequent observations must be compatible with.

Further philosophical note of caution: saying that the observers were \textit{not} in an interacting configuration is \textit{not} the same as saying that they were in a non-interacting one. Those configurations are more about book-keeping.

\subsubsection{Why Does This Not Break Things?}

It \textit{does}! My evolution is no longer strictly unitary. Instead, at interaction, we enter a mixed state.

Here is how I see my work in comparison to Barandes' work whose philosophy may appear vaguely similar to mine (which is why I include him here): I admit that I have not looked super deeply into Barandes' work, but I have seen that he derives the Born rule from his axioms and it seems like he finds a "good" place where to apply it consistently. I think that finding this "good place" has a whole lot to do with him using a Cartesian configuration space. I think it is well established that the Born rule can not fit into unitary evolution (which is equivalent to the Schrödinger equation). So, either his derivation of the Born rule relies on some implicit assumption (in which case he might be reproducing my picture but in a complicated unistochastic language, or something else entirely) or his proof that his axioms reproduce unitary evolution would seem to be wrong.

Here is how I reason about why the differences between my dynamics and unitary evolution may so far not have been observed:

\begin{itemize}
\item In the case that a single particle and a measurement device are the only thing that ever interacts, this produces the correct predictions by construction.

\item Experiments that care mostly about entanglement work whether or not an interaction actually happens. 

\item In the case of particles interacting in the wild, the interactions are too rare to meaningfully contribute to overall predictions.

\item In situations like interferometers, I assume that even there, the contribution of actual interactions are negligible, and it would be rather difficult to separate these cases from environmental influences. Running this particular math is \textit{way} out of scope for this contribution though. But once it is done, one might be able to \textit{test} this by checking after interference failure whether the particles are still correlated. If the correlation is slightly stronger than predicted purely from environmental influences, that would prove me right.
\end{itemize}

Regarding the last part: I want to emphasize again that doing the math to find out what my model actually predicts how often this "collapse at interaction" happens is, while conceptually possible, way out of scope for this contribution. I also want to mention that if the effect is exceptionally tiny, one would have to come up with an extremely exact model for environmentally induced decoherence to even devise an experiment that could pass the $10\sigma$ detection bound. But it \textit{is} conceptually possible.

In other words: this is a \textit{good} adjustment - because there is a good chance that the empirical implications on the dynamics could have been missed so far, yet my model makes a prediction here.

Honestly, it would seem that this is just something that hitherto, nobody has seriously considered - even though the philosophy (interaction as such can lead to measurement) was there at least since Everett. Yes: there are spontaneous collapse models, but none of them are tied to interaction. The only concern about including this as another axiom was "but it would break unitary evolution!"

\textit{And}? So long as we break it subtly and in a well-motivated way that makes our understanding \textit{more} consistent, that shouldn't be a problem, right? When the math gives us no reason to assume that the Born rule ought to be applied only in special situations and philosophy demands laws of the universe to be - well - universal, this fix is probably a good idea.

It was only upon further reflection that it occurred to me that the conventional choice to represent unitary evolution via tensor math (which I ditched \textit{solely} on the ground that I didn't understand why it was "necessary") may have contributed to people not daring to make this move: they did not quite know how to. If your formalism is solipsistic and interaction is more of an embarrassing practical necessity imposed from outside the map, it's difficult to even \textit{imagine} how to do this. And imagine encoding this refinement into a modified Schrödinger equation - oh, the horror!

The only thing that you have to swallow is that we no longer have a \textit{group} of linear operators to encode evolution, but a only monoid, as the Born rule - while it \textit{does} preserve the norm - is \textit{not} injective. Or, if you represent the system as multiple individual agents (sparse encoding for practical numerical computations), it becomes a category with some lossy morphisms (which leads to a reinterpretation of path integrals in general as repeated morphism chaining in a suitable category and "making the morphisms shorter" as we take $dt\to 0$). But weren't y'all hunting for the holy grail of why the past appears different from the future? Well, there's your answer: it's because it \textit{is} different from the future.

But this is not all this notational tweak does! On top of making Quantum Mechanics make sense, it enables us to think of imposing constraints like Lorentz invariance in a whole new way:

Let $S$ be the global configuration space (a Cartesian product over the possible configurations or all protagonists) and $\mathrm{Iso}(S)$ be the isomorphism group on S.

Let $G_I$ be a family of groups with index set $I$ encoding the symmetries we care about: Galilean symmetry, Lorentzian symmetry - you name it. Now, define

\begin{align*}
\mathrm{Iso}(S) \supseteq G := \bigcap_{i\in I}\mathrm{img}(f_i(G_i))
\end{align*}

for a family of group embeddings $f_i$ into $\mathrm{Iso}(S)$ associated with each $G_i$.

Our dynamic operator $P$ must be a \textit{global} linear unitary map $P:\mathbb{C}^S\longmapsto\mathbb{C}^S$ such that for all $f\in G$

$$\hat{f}\circ P\circ \hat{f}^{-1} = P,$$

where

\begin{align*}
\hat{f}:\mathbb{C}^S &\longmapsto \mathbb{C}^S,\\ \hat{f}(\phi_s) &\mapsto \phi_{f(s)}.
\end{align*}

That's a trick we have - to my knowledge - hitherto been using on \textit{each object's} Hilbert space, but never on a global Hilbert space encoding the big picture. Here, it is straightforward, for example, to tie a coordinate transformation in one particle's position/momentum space to that of another particle.

After finding our evolution operator, incorporating my collapse dynamics is a mechanical transformation which is optional in scenarios where the weight of the Born branches can be considered negligible.

Oh, and to fully incorporate my first postulate and make this truly Lorentz compatible, one probably has to impose symmetry constraints on the time dimension (which so far was just a parameter to index our unitary operators!) as well and think carefully about what that means. In particular, I expect a stark asymmetry between the known past and the unknown future.

\subsection{Research Directions}

\begin{enumerate}

\item I have given a novel way to inject Lorentz invariance - or any other symmetry we care about - into the search criteria for dynamic operators in the path integral formalism. But at least, we have a new way to even look for an answer and I hope that this will produce results that differ in fundamental ways from QFT. This would be exciting, and the predictions coming out of \textit{this} would probably be testable much sooner than my Born rule idea.

\item The reason why I think QFT could be sidestepped is not just because fields were basically a mathematical hack to solve inconsistencies when imposing Lorentz invariance naively in a particle-theoretical setting. The other reason is that the relational picture naturally leads to a different way to think about how fermions "emit" bosons: rather than "exciting a field", I think of the process as, say, an electron just constantly attempting to emit a photon - but this only becomes real when the photon actually hits something. This \textit{naturally} leads to a more Lorentzian picture of the system's dynamics where an interaction has to be thought of as local to the receiver and boils down to a ton of logical constraints snapping into place and leaving a footprint in the system's correlations. Basically, an interaction triggers a giant belief-propagation.

\item General Relativity suggests that gravity is just coordinate-frame carrying masses fighting it out with each other, constantly trying to reconcile their different notions of up, down, left, right, back, forth, past and future. With my picture of Quantum Mechanics, \textit{this makes sense now} at the quantum level: No more discretization of spacetime, no more quantum foam, no more Calabi-Yaus. Particles are \textit{real} at interactions and this reality leaves a trace, and outside of interactions, you can not say anything. They \textit{carry} their own coordinate system, and they fight it out through interactions.

\item Personally, I find it very satisfying that treating epistemic wave functions as ontic solves things philosophically. You know what would be even greater? If we could somehow treat the wave function as latent in the correlation between interaction-facts (that is: the real statistical trace left behind by interactions, \textit{not} the mathematical ghosts moving through Hilbert spaces). The idea that quantum information could just be living in correlations of interaction-facts - extending that in such a way that material agents express their quantum expectations in the correlations of interaction-facts would be huge. Don't forget: quantum mechanics lives in books, storage devices and our material practice, not some otherworldy Platonic ideals.

\item This leads me to a "second decoherence conjecture": can we find, in this new version of quantum mechanics, some explanation why sufficiently complex quantum agents would be interested in bringing the universe \textit{for itself} (onto-epistemic wave function) in congruence with the universe \textit{in itself} (record trace of interaction-facts)? At least, we have for the first time a probabilistic calculus that allows the system to reason about itself, so we can treat this question \textit{in the model}.

\end{enumerate}

\pagebreak

\section{Acknowledgements}

\blockquote[Immanuel Kant]{
Enlightenment is man's emergence from his self-imposed immaturity. Immaturity is the inability to use one’s understanding without guidance from another. This immaturity is self-imposed when its cause lies not in lack of understanding, but in lack of resolve and courage to use it without guidance from another. Sapere Aude! 'Have courage to use your own understanding!' - that is the motto of enlightenment.
}

\textbf{Dedicated to my wife whom I love from the bottom of my heart.}\\

\href{https://x.com/comradeKangaroo}{Find me on social media}

\pagebreak

\printbibliography

\end{document}